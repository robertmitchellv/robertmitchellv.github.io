{
  "hash": "39e4f9041977a16556f85630c78e4e34",
  "result": {
    "markdown": "---\ntitle: \"First Kaggle Submission--Random Forest Classifier\"\nauthor: \"Robert Mitchell\"\ndate: \"January 23, 2015\"\ncategories: [Python, SciKit-Learn, Random Forests, Outdated]\n---\n\n\n::: {.callout-important}\nThis is a very old post. Please check the `sklearn` documentation for examples of how to run a Random Forest Classifier. This remains here as a record for myself \n:::\n\n\n\n\n\nI have seen kaggle mentioned on twitter a lot; mostly by the data scientists and researchers I look up to, but there's never been much confidence that the site was for me in any way---mostly because I was a long way from my dream data science job with yet so much to learn.  Notwithstanding, I cannot help but try and hack my way to my destination!  I think it's a part of my learning process: thrust myself in the midst of something I don't understand, get stuck, try to get unstuck, finish with some understanding of what I was doing.\n\n<br>\n\nSo, when I saw [this](http://http://blog.kaggle.com/2012/07/02/up-and-running-with-python-my-first-kaggle-entry/\"Up and Running with Python\") post by [Chris Clark](https://github.com/chrisclark \"Chris's GitHub Profile\"), I thought that it was about time I try and hack my way from recently learning Python to machine learning with SciKit-Learn&---why not!?&---I thought.\n\n<br>\n\nIt reminded me of when I decided to sign up with an account at GitHub; I was initially intimidated because it was new to me.  Now, I use git in the command line, host my website there, and use it for almost everything (still learning new things about git everyday as well).\n\n<br>\n\nChris's post was excellent but there was one problem: the code was aimed at Python 2.7 users and I had just spent the previous semester learning Python 3 (which means I don't really know 2.7; and avoid it all the time \"where are the parens for this print statement??\").  As a personal challenge, I decided to use the code and update it to Python 3, which was both fun and challenging (I'm measuring 'update' to mean, 'running in my Python 3.4 interpreter without error messages').  This may be an easy task but there were a few snags for me. \n\n<br>\n\nIn the spirit of trying to document the things I learn, I've decided to chronical my results here&---if there are any errors or issues with this code, please let me know so I can try to correct, learn, and grow!  I also found Chris's updated code on GitHub, which uses Pandas and I've been trying to get started with Pandas as well so; win, win.\n\n<br>\n\nAs an aside, I use Anaconda and Vim for the enviornment and editing, respectively.  My code can be found on [GitHub](https://github.com/robertmitchellv/kaggle/tree/master/Predicting-a-Biological-Response \"robertmitchellv\").\n\n<br>\n\nThe Submission was a part of the [Predicting a Biological Response](https://www.kaggle.com/c/bioresponse) competition, and the training, test, and benchmark data sets are provided.\n\n<br>\n\nSince the competition wants us to predict binary values, Chris notes that this data set is a good introduction to ensemble classifiers, because the prediction is a binary value (0 or 1).  It was also great to take a closer look at both the Pandas and SciKit-Learn's documentation to troubleshoot. I tried to use the comments to explain as much as possible so future me will not be baffled, which I can say is helpful since I'm looking at this one month out and it makes total sense (at least to me).\n\n<br>\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n### Kaggle Submission Code\n\"\"\"\n    //kaggle submission\n    //Biological Response\n    --> random forest classifier\n\n    Author: Robertmitchellv\n    Date: Dec 16, 2104\n    Revised: Dec 22, 2014\n\"\"\"\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\n\ndef main():\n    # create the training + test sets\n    try:\n        data = pd.read_csv('Data/train.csv')\n    except IOError:\n        print(\"io ERROR-->Could not locate file.\")\n\n    target = data.Activity.values\n\n    train = data.drop('Activity', axis = 1).values\n\n    test = pd.read_csv('Data/test.csv').values\n\n    # create and train the random forest and call it 'rf'\n    # --> n_estimators = the number of trees in this forest, viz.\n    #     100 trees of forest\n    # --> n_jobs set to -1 will use the number of cores present on your system.\n    rf = RandomForestClassifier(n_estimators = 100, n_jobs = -1)\n    # fit(X, y[, sample_weight]) = build a forest of tress from the\n    # training set (X, y)\n    rf.fit(train, target)\n\n    # predict_proba(X) predict class probabilities for X as list\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\n\n    # prep data for use in pd.Series\n    molID, predictProbs = prepData(predicted_probs)\n\n    # use a dictionary with keys as col headers and values as lists pulled from\n    # previous prep function\n    df = {'MoleculeID': molID, 'PredictedProbability': predictProbs}\n\n    # pandas DataFrame = a tabular datastructure like a SQL table\n    predicted_probs = pd.DataFrame(df)\n\n    # write predicted_probs to file with pandas method .to_csv()--add header\n    # for submission\n    try:\n        predicted_probs.to_csv('Data/submission.csv', index = False)\n        print(\"File successfully written; check 'Data' folder\")\n    except IOError:\n        print(\"io ERROR-->Could not write data to file.\")\n\n# preparing data for conversion to pd.DataFrame\ndef prepData(alist):\n        # prepare list to be converted to pandas Series\n        colOne = []\n        colTwo = []\n        idx = 1\n\n        # for loop to set MoleculeID to match the benchmark;\n        # place values into list for easier wrangling as pd.Series\n        for i in alist:\n            colOne.append(idx)\n            colTwo.append(i)\n            idx += 1\n\n        return colOne, colTwo\n\n# call the main function\nmain()\n```\n:::\n\n\n<br>\n\nAfter performing this--Chris suggested to submit to kaggle; being an extra careful person by nature, I just had to perform the evaluation and cross validation first (I don't know if any of you feel the same way).  Unfortunately, I don't really understand how the code works--this is one of the problems when hacking through tutorials.  \n\n<br>\n\n\n::: {.cell}\n\n```{.python .cell-code}\n### Evaluation/Logloss\n\"\"\"\n    //kaggle submission\n    //Biological Response\n    --> evaluation function (from Grunthus' post)\n\"\"\"\n\nimport scipy as sp\n\ndef logloss(act, pred):\n    \"\"\" Vectorised computation of logloss \"\"\"\n\n    #cap in official Kaggle implementation,\n    #per forums/t/1576/r-code-for-logloss\n    epsilon = 1e-15\n    pred = sp.maximum(epsilon, pred)\n    pred = sp.minimum(1-epsilon, pred)\n\n    #compute logloss function (vectorised)\n    ll = sum(   act*sp.log(pred) +\n                sp.subtract(1,act)*sp.log(sp.subtract(1,pred)))\n    ll = ll * -1.0/len(act)\n    return ll\n```\n:::\n\n\n<br>\n\nThe cross validation was trickier to understand, which I think is mostly due to my not really understanding what ensemble classifiers do, how the random forest classifier works, and more specifically; what training, test, and target data do within machine learning.  This gave chase through the SciKit-Learn documentation and other resources online to get a better understanding of what the code was doing&---there's a lot to learn!  The interesting aspect is how the SciKit-Learn reserves some actual data that it can test against the classifier's predicted values.  I tried to show in the\ncomments how I was understanding what the code did at the time.\n\n<br>\n\n\n::: {.cell}\n\n```{.python .cell-code}\n### Cross Validation\n\"\"\"\n    //kaggle submission\n    //Biological Response\n    --> cross validation\n\"\"\"\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.cross_validation import KFold\nimport numpy as np\nimport pandas as pd\nimport logloss\n\ndef main():\n    #read data from csv; use nparray to create the training + target sets\n    try:\n        train = pd.read_csv('Data/train.csv')\n    except IOError:\n        print(\"io ERROR-->Could not locate file.\")\n\n    target = np.array([x[0] for x in train])\n    train = np.array([x[1:] for x in train])\n\n    # in this case we'll use a random forest, but this could be any classifier\n    model = RandomForestClassifier(n_estimators = 100, n_jobs = -1)\n\n    # simple K-Fold cross validation. 10 folds.\n    cv = KFold(n = len(train), n_folds = 10, indices = False)\n\n    #iterate through the training and test cross validation segments and\n    #run the classifier on each one, aggregating the results into a list\n    results = []\n    for traincv, testcv in cv:\n        prob = model.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\n        results.append(logloss.llfun(target[testcv], [x[1] for x in prob]))\n\n    #print out the mean of the cross-validated results\n    print('Results: ', str(np.array(results).mean()))\n\n# call main function\nmain()\n```\n:::\n\n\n<br>\n\nAfter I was able to execute the submission, logloss, and cross validation code without any errors, I submitted my code to kaggle.  It was an exciting moment waiting to see what kind of score I would have recieved had I actually participated in the competition.  I would have placed at 325 (well, I would have tied with another user for 325th); check out my results below.\n\n<br>\n\n<img src=\"https://raw.githubusercontent.com/robertmitchellv/kaggle/master/Predicting-a-Biological-Response/kaggle_leaderboard.png\" width=\"800px\" height=\"auto\">\n\n<br>\n\nWell, that wraps up my first submission to kaggle.  I really hope this is the first of many.  Right now I'm working through the Think Stats + Think Bayes books to refresh my stats knowledge.  I'm trying to find time to work on the Titanic tutorial through kaggle as well as perhaps throw a hat in the ring for Booz Hamilton's Data Science Bowl.  There's so much to learn and I can't wait for these concepts to become more natural and familiar.\n\n<br>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}