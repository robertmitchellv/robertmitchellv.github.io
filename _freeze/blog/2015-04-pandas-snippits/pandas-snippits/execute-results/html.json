{
  "hash": "b2666a72a7e708c07ae124f0aca0b088",
  "result": {
    "markdown": "---\ntitle: \"My `pandas` snippets--always evolving\"\nauthor: \"Robert Mitchell\"\ndate: \"April 3, 2015\"\ncategories: [Python, Pandas, Outdated]\n---\n\n\n::: {.callout-important}\nThis is a very old post. The `pandas` API has matured greatly and most of this is very outdated. This remains here as a record for myself \n:::\n\n\n\n\n\n<br>\n\nThe goal of this post is to keep me from googling pandas questions that I've forgotten.  I don't know how many times I've looked at the results and seen five or more StackOverflow links that have clearly already been clicked on; I feel like Sisyphus when this happens!  So, here is what I'm currently committing to memory:\n\n<br>\n\n\n::: {.cell}\n\n```{.python .cell-code}\n### Make matplotlib.pyplot look better with no effort:\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\n\n### Delete column\ndel df['colName']\n\n\n### Rename columns\ndf.columns = ['col1', 'col2', 'col3'] # this does not reindex columns\n\n### Combine columns\ndf['newCol'] = df['col1'].map(str) + data['col2'] + data['col3'].astype('str')\n\n### Copy column\ndf['newCol'] = df['oldCol'] # where newCol is the copy\n\n\n### Reindex columns\ncols = ['col1', 'col2', 'col3', 'col4'] # list of how you'd like it\ndf = df.reindex(columns=cols)\n\n\n### Find out how many NaN values you have in a column\ndf['colName'].isnull().sum()\n\n\n### Show unique values\ndf[df['colName'].unique()]\n\n### Create a frequency column from another column\ndf['freq'] = df.groupby('colName')['colName'].transform('count')\n\n### Delete row\ndf = df.drop(2)  # where two is the df's index\ndf = df.drop('rowName')  # if you reindexed\n\n\n### Remove characters before a specific character\ndf['colName'] = df['colName'].apply(lambda x: x.split('-')[-1]) # char = -\n\n\n### Remove characters after a specific character\ndf['colName'] = df['colName'].apply(lambda x: x.split('-')[0]) # char = -\n\n\n### Remove characters, e.g., commas from data\ndf['colName'] = df['colName'].str.replace(',', '')\n\n\n### Convert datatypes, e.g., object to float\ndf[['col4', 'col5', 'col10']] = df[['col4', 'col5', col10]].astype(float)\n\n\n### Convert string date to datetime64\ndf['strDate'] = pd.to_datetime(df['strDate'])\n\n\n### Filter datetime64 column values\nimport datetime\ndf[df['colName'] >= datetime.date(2015, 1, 1)]\n\n\n### Convert NaN values to zeros (or anything else)\ndf = df.fillna(0) # remember that this returns a new object!\n\n\n### Replace string values with numeric representations\ndictionary = {'value1': 1, 'value2': 2, 'Value3': 3}\ndf = df.replace({'colName': dictionary})\n\n\n### Replace multiple cells of a column only with a different string\ndf.loc[df['colName'].str.contains('word'), df['colName']] = \"Different Word\" # or\ndf.loc[df['colA'].str.contains('word'), ['colB']] = 5 # to change a cell in a different column\n\n\n### Project data based on a value range from a column\ndf[df.colWithNumbers <= 360] # shows me values less than or equal to 360\ndf[df['colWithStrings'].str.contains(\"word\")] # shows me values with 'word' in them\n\n\n### Project data based on two values (use and or pipe symbol to denote relationship)\ndf[(df['colWithString'].str.contains(\"word\")) & (df.colWithNumber <= 5)] # and\ndf[(df['colWithString'].str.contains(\"firstWord\")) | (df['colWithString'].str.contains(\"secondWord\"))] # or\n\n\n### Groupby as variable\ngroupedby = df.groupby(df.colName) # or:\ngroupedby = df.groupby(df.colName).add_suffix('/Mean') # add column suffixes\n\n\n### Use groupedby variable and find the mean for your values\ngroupedbyMean = groupedby.mean()\n```\n:::\n\n\n<br>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}